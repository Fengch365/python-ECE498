{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.factors.discrete import DiscreteFactor\n",
    "from pgmpy.models import FactorGraph\n",
    "from pgmpy.inference import BeliefPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76225608, 0.864833  , 0.56522779, 0.96563802])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = FactorGraph() ## Create FactorGraph object\n",
    "#G.add_nodes_from()\n",
    "###############################\n",
    "#   TODO: Define factor functions\n",
    "###############################\n",
    "f_1 = DiscreteFactor(['S1'],[2],[8.5,1.5])\n",
    "f_2 = DiscreteFactor(['S1','E1'],[2,2],[1.,2.,0.,5.])\n",
    "\n",
    "###############################\n",
    "#   TODO: Add random variables\n",
    "#         and factor functions \n",
    "###############################\n",
    "G.add_nodes_from(['E1', 'S1'])  ## Add random variables \n",
    "G.add_factors(f_1,f_2)     ## Add factor functions\n",
    "\n",
    "###############################\n",
    "#   TODO: Add the edges for random \n",
    "#   variables and factor functions\n",
    "###############################\n",
    "G.add_edges_from([('S1',f_1), ('S1',f_2), ('E1',f_2)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eliminating: E1: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 338.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "| S1    |   phi(S1) |\n",
      "+=======+===========+\n",
      "| S1(0) |   25.5000 |\n",
      "+-------+-----------+\n",
      "| S1(1) |    7.5000 |\n",
      "+-------+-----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bp = BeliefPropagation(G)\n",
    "###############################\n",
    "#   TODO: Compute the marginal probability\n",
    "###############################\n",
    "margin = bp.query(variables=['S1'],evidence=[])\n",
    "#dir(margin)\n",
    "print(margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S1 = 0 maximizes the marginal probability P(S1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "| S1    |   phi(S1) |\n",
      "+=======+===========+\n",
      "| S1(0) |   17.0000 |\n",
      "+-------+-----------+\n",
      "| S1(1) |    7.5000 |\n",
      "+-------+-----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bp1 = BeliefPropagation(G)\n",
    "###############################\n",
    "#   TODO: Compute the marginal probability\n",
    "###############################\n",
    "margin1 = bp1.query(variables=['S1'],evidence={'E1':1},)\n",
    "#dir(margin)\n",
    "print(margin1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S1 = 0 maximizes the probability P(S1|E1=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2:\n",
    "\n",
    "P(S1=0) = f(S1=0)*(g(S1=0,E1=0)+g(S1=0,E1=1))= 25.5\n",
    "\n",
    "P(S1=1) = f(S1=1)*(g(S1=1,E1=0)+g(S1=1,E1=1))= 7.5\n",
    "\n",
    "2.4:\n",
    "\n",
    "P(S1=0|E1=1) = f(S1=0)*g(S1=0,E1=1) = 17\n",
    "\n",
    "P(S1=1|E1=1) = f(S1=1)*g(S1=1,E1=1) = 7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTACK_EVENTS_MAP = {\n",
    "    'Scan':1,\n",
    "    'Login':2,\n",
    "    'Sensitive_URI':3,\n",
    "    'New_Kernel_Module':4,\n",
    "    'DNS_Tunneling':5\n",
    "}\n",
    "ATTACK_STATES_MAP = {\n",
    "    'benign': 1,\n",
    "    'discovery': 2,\n",
    "    'access': 3,\n",
    "    'lateral_movement': 4,\n",
    "    'privilege_escalation': 5,\n",
    "    'persistence': 6,\n",
    "    'defense_evasion': 7,\n",
    "    'collection': 8,\n",
    "    'exfiltration': 9,\n",
    "    'command_control': 10,\n",
    "    'execution': 11\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.936     , 0.064     , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.55333333, 0.        , 0.        , 0.        , 0.44666667,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.875     , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.125     , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.02      , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.98      , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_review = open('event_review.txt', 'r') \n",
    "Lines = event_review.readlines() \n",
    "f_gen=np.zeros((5,11))\n",
    "for line in Lines: \n",
    "    temp = line.split(\" //\")\n",
    "    temp[0] = temp[0][7:]\n",
    "    temp[1] = temp[1].strip('/')\n",
    "    temp[1] = temp[1].strip('\\n')\n",
    "    temp[1] = temp[1][21:]\n",
    "    temp[1] = temp[1].strip(\" \")\n",
    "    #print(ATTACK_EVENTS_MAP[temp[0]]-1,ATTACK_STATES_MAP[temp[1]]-1)\n",
    "    f_gen[ATTACK_EVENTS_MAP[temp[0]]-1,ATTACK_STATES_MAP[temp[1]]-1] = f_gen[ATTACK_EVENTS_MAP[temp[0]]-1,ATTACK_STATES_MAP[temp[1]]-1] +1.0\n",
    "for i in range(5):\n",
    "    f_gen[i,:]=f_gen[i,:]/f_gen[i,:].sum()\n",
    "f_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Event Sequence is  Scan->Sensitive_URI->New_Kernel_Module \n",
      "the Probability is 0.07147962830593281\n"
     ]
    }
   ],
   "source": [
    "attack_sequences = open('attack_sequences.txt', 'r') \n",
    "Lines = attack_sequences.readlines()\n",
    "pattern={}\n",
    "total = 0\n",
    "for line in Lines:\n",
    "    #print(line)\n",
    "    #line.rstrip('\\n')\n",
    "    temp = line.rstrip(' \\n').split(\" \")\n",
    "    #print(temp)\n",
    "    for i in range(len(temp)-2):\n",
    "        total+=1\n",
    "        key = temp[i]+'->'+temp[i+1]+'->'+temp[i+2]\n",
    "        if(key in pattern):\n",
    "            pattern[key]=pattern[key]+1\n",
    "        else:\n",
    "            pattern[key]=1\n",
    "maximum = max(pattern, key=pattern.get)\n",
    "possibility = pattern[maximum]/total\n",
    "print(\"Most Common Event Sequence is \",maximum,\"\\nthe Probability is\", possibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Most Common Event Sequence</th>\n",
       "      <th>Factor Function</th>\n",
       "      <th>Attack States</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scan-&gt;Sensitive_URI-&gt;New_Kernel_Module</td>\n",
       "      <td>c</td>\n",
       "      <td>persistence</td>\n",
       "      <td>0.07148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Most Common Event Sequence Factor Function Attack States  \\\n",
       "0  Scan->Sensitive_URI->New_Kernel_Module               c   persistence   \n",
       "\n",
       "   Probability  \n",
       "0      0.07148  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca = [maximum]\n",
    "cb = [\"c\"]\n",
    "cc = ['persistence']\n",
    "cd  = [possibility]\n",
    "table = pd.DataFrame({\"Most Common Event Sequence\": ca, \"Factor Function\": cb,\"Attack States\": cc, \"Probability\": cd})\n",
    "\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sensitive_URI->Sensitive_URI->Sensitive_URI': 186, 'Login->Login->Login': 7, 'Scan->Scan->Scan': 25, 'New_Kernel_Module->New_Kernel_Module->New_Kernel_Module': 25, 'DNS_Tunneling->DNS_Tunneling->DNS_Tunneling': 15}\n",
      "186\n",
      "Most frequent repetitive Event Sequence is  Sensitive_URI->Sensitive_URI->Sensitive_URI \n",
      "the Probability is 0.06647605432451752\n"
     ]
    }
   ],
   "source": [
    "attack_sequences = open('attack_sequences.txt', 'r') \n",
    "Lines = attack_sequences.readlines()\n",
    "patternr={}\n",
    "for line in Lines:\n",
    "    #print(line)\n",
    "    #line.rstrip('\\n')\n",
    "    temp = line.rstrip(' \\n').split(\" \")\n",
    "    #print(temp)\n",
    "    for i in range(len(temp)-2):\n",
    "        if(temp[i]==temp[i+1] and temp[i+2]==temp[i+1]):\n",
    "            key = temp[i]+'->'+temp[i+1]+'->'+temp[i+2]\n",
    "            if(key in patternr):\n",
    "                patternr[key]=patternr[key]+1\n",
    "            else:\n",
    "                patternr[key]=1\n",
    "print(patternr)\n",
    "maximumr = max(patternr, key=patternr.get)\n",
    "possibilityr = patternr[maximumr]/total\n",
    "print(patternr[maximumr])\n",
    "print(\"Most frequent repetitive Event Sequence is \",maximumr,\"\\nthe Probability is\", possibilityr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Most Common Event Sequence</th>\n",
       "      <th>Factor Function</th>\n",
       "      <th>Attack States</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sensitive_URI-&gt;Sensitive_URI-&gt;Sensitive_URI</td>\n",
       "      <td>r</td>\n",
       "      <td>privilege escalation</td>\n",
       "      <td>0.066476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Most Common Event Sequence Factor Function  \\\n",
       "0  Sensitive_URI->Sensitive_URI->Sensitive_URI               r   \n",
       "\n",
       "          Attack States  Probability  \n",
       "0  privilege escalation     0.066476  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca = [maximumr]\n",
    "cb = [\"r\"]\n",
    "cc = ['privilege escalation']\n",
    "cd  = [possibilityr]\n",
    "table = pd.DataFrame({\"Most Common Event Sequence\": ca, \"Factor Function\": cb,\"Attack States\": cc, \"Probability\": cd})\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2  You will have to submit the graph you draw through Compass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_review = open('event_review.txt', 'r') \n",
    "Lines = event_review.readlines() \n",
    "f_gen=np.zeros((5,11))\n",
    "for line in Lines: \n",
    "    temp = line.split(\" //\")\n",
    "    temp[0] = temp[0][7:]\n",
    "    temp[1] = temp[1].strip('/')\n",
    "    temp[1] = temp[1].strip('\\n')\n",
    "    temp[1] = temp[1][21:]\n",
    "    temp[1] = temp[1].strip(\" \")\n",
    "    #print(ATTACK_EVENTS_MAP[temp[0]]-1,ATTACK_STATES_MAP[temp[1]]-1)\n",
    "    f_gen[ATTACK_EVENTS_MAP[temp[0]]-1,ATTACK_STATES_MAP[temp[1]]-1] = f_gen[ATTACK_EVENTS_MAP[temp[0]]-1,ATTACK_STATES_MAP[temp[1]]-1] +1.0\n",
    "for i in range(5):\n",
    "    f_gen[i,:]=f_gen[i,:]/f_gen[i,:].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. At every time point, provide the marginal probability of each state (Since we have 9 time points and 11 possible states, you should provide 99 probability values here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. At every time point, provide the most probable state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS = {\n",
    "    # each value in an actions' vector corresponds to an attack stage\n",
    "    'NO-OP':   [1.,   0.61, 0.69, 0.09, 0.2 , 0. ,  0.,   0.,   0. ,  0. ,  0.  ],\n",
    "    'MONITOR': [0.  , 0.39, 0.31 ,0.84, 0.63, 0.7,  0.07 ,0.1 , 0. ,  0. ,  0.  ],\n",
    "    'STOP':    [0.  , 0.,   0.  , 0.07, 0.17, 0.3,  0.93 ,0.9 , 1. ,  1. ,  1.  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicate the earliest stage in which your model should recommend stopping the attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Judge whether the most probable states for $s_1-s_6,s_8,s_9$ remain the same as Task3.2\n",
    "#### b. State the reason for your judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_review = open('event_review.txt', 'r') \n",
    "Lines = event_review.readlines() \n",
    "f_gen=np.zeros((5,11))\n",
    "for line in Lines: \n",
    "    temp = line.split(\" //\")\n",
    "    temp[0] = temp[0][7:]\n",
    "    temp[1] = temp[1].strip('/')\n",
    "    temp[1] = temp[1].strip('\\n')\n",
    "    temp[1] = temp[1][21:]\n",
    "    temp[1] = temp[1].strip(\" \")\n",
    "    #print(ATTACK_EVENTS_MAP[temp[0]]-1,ATTACK_STATES_MAP[temp[1]]-1)\n",
    "    f_gen[ATTACK_EVENTS_MAP[temp[0]]-1,ATTACK_STATES_MAP[temp[1]]-1] = f_gen[ATTACK_EVENTS_MAP[temp[0]]-1,ATTACK_STATES_MAP[temp[1]]-1] +1.0\n",
    "for i in range(5):\n",
    "    f_gen[i,:]=f_gen[i,:]/f_gen[i,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_c=[0.07147962830593281,0,0,0,0,0,0,0,0,0,0]\n",
    "f_r=[0.06647605432451752,0,0,0,0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = FactorGraph() ## Create FactorGraph object\n",
    "###############################\n",
    "#   TODO: Define factor functions\n",
    "###############################\n",
    "f_1 = DiscreteFactor(['E1','S1'],[1,11],f_gen[0])\n",
    "#f_2 = DiscreteFactor(['E2','S2'],[1,11],f_gen[1])\n",
    "f_3 = DiscreteFactor(['E3','S3'],[1,11],f_gen[2])\n",
    "f_4 = DiscreteFactor(['E4','S4'],[1,11],f_gen[2])\n",
    "f_5 = DiscreteFactor(['E5','S5'],[1,11],f_gen[2])\n",
    "f_6 = DiscreteFactor(['E6','S6'],[1,11],f_gen[3])\n",
    "#f_7 = DiscreteFactor(['E7','S7'],[1,11],f_gen[4])\n",
    "#f_8 = DiscreteFactor(['E8','S8'],[1,11],f_gen[4])\n",
    "#f_9 = DiscreteFactor(['E9','S9'],[1,11],f_gen[4])\n",
    "\n",
    "r = DiscreteFactor(['E3','E4','E5','S5'],[1,1,1,11],f_r)\n",
    "c = DiscreteFactor(['E1','E3','E6','S6'],[1,1,1,11],f_c) \n",
    "###############################\n",
    "#   TODO: Add random variables\n",
    "#         and factor functions \n",
    "###############################\n",
    "G1.add_nodes_from(['E1','E3','E4','E5','E6','S1','S3','S4','S5','S6'])  ## Add random variables \n",
    "G1.add_factors(f_1,f_3,f_4,f_5,f_6,r,c)     ## Add factor functions\n",
    "\n",
    "###############################\n",
    "#   TODO: Add the edges for random \n",
    "#   variables and factor functions\n",
    "###############################\n",
    "G1.add_edges_from([('E1',f_1),('S1',f_1),('E3',f_3),('S3',f_3),('E4',f_4),('S4',f_4),('E5',f_5),('S5',f_5),('E6',f_6),('S6',f_6),('E1',c),('E3',c),('E6',c),('S6',c),('E3',r),('E4',r),('E5',r),('S5',r)])\n",
    "\n",
    "###############################\n",
    "#   TODO: Do the inference\n",
    "###############################\n",
    "bp1 = BeliefPropagation(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = FactorGraph()\n",
    "f_2 = DiscreteFactor(['E2','S2'],[1,11],f_gen[1])\n",
    "G2.add_nodes_from(['E2','S2'])\n",
    "G2.add_factors(f_2)\n",
    "G2.add_edges_from([('E2',f_2),('S2',f_2)])\n",
    "bp2 = BeliefPropagation(G2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G4 = FactorGraph()\n",
    "f_8 = DiscreteFactor(['E8','S8'],[1,11],f_gen[4])\n",
    "G4.add_nodes_from(['E8','S8'])\n",
    "G4.add_factors(f_8)\n",
    "G4.add_edges_from([('E8',f_8),('S8',f_8)])\n",
    "bp4 = BeliefPropagation(G4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G5 = FactorGraph()\n",
    "f_9 = DiscreteFactor(['E9','S9'],[1,11],f_gen[4])\n",
    "G5.add_nodes_from(['E9','S9'])\n",
    "G5.add_factors(f_9)\n",
    "G5.add_edges_from([('E9',f_9),('S9',f_9)])\n",
    "bp5 = BeliefPropagation(G5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_s1=bp1.query(variables=['S1']).normalize(inplace=False)\n",
    "print(margin_s1)\n",
    "margin_s3=bp1.query(variables=['S3']).normalize(inplace=False)\n",
    "print(margin_s3)\n",
    "margin_s4=bp1.query(variables=['S4']).normalize(inplace=False)\n",
    "print(margin_s4)\n",
    "margin_s5=bp1.query(variables=['S5']).normalize(inplace=False)\n",
    "print(margin_s5)\n",
    "margin_s6=bp1.query(variables=['S6']).normalize(inplace=False)\n",
    "print(margin_s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_s2=bp2.query(variables=['S2']).normalize(inplace=False)\n",
    "print(margin_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_s8=bp4.query(variables=['S8']).normalize(inplace=False)\n",
    "print(margin_s8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_s9=bp5.query(variables=['S9']).normalize(inplace=False)\n",
    "print(margin_s9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 a)  Based on the calculated marginal probability for S1-S6,S8,S9, we infer the most probable hidden state are as follows: t=1,Benign; t=2, Benign; t=3, Benign; t=4, Benign; t=5,Benign; t=6,Benign; t=8, Extracton; t=99,Extraction\n",
    "#### b) The most probable hidden states for S1-S6,S8,S9 remain the same. Because the E7 and S7 consist a independent factor graph( the graph have no connection with any other factor graphs), which means that S1-S6,S8,S9 are independent of E7 and S7. So delete E7 and S7 will not affect the S1-S6,S8,S9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Draw an HMM model for the attack scenario given the provided states and events.\n",
    "#### b. What parameters are needed for this HMM model to work?\n",
    "#### c. Give an example of an advantage of the FG over the HMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
