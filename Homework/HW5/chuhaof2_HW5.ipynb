{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  From .csv file, read headers, then load numbers into array x\n",
    "#  Warning: unfortunately there are many types of .csv files\n",
    "#  This code assumes the .csv file has comma separate headings in the first row\n",
    "#  and comma separated numbers in the remaining rows.\n",
    "def data_load(string):\n",
    "    csv_path = string\n",
    "    with open(csv_path,'rt') as csvfile:  #After code under \"with open as\" is completed, csvfile is closed\n",
    "        reader=csv.reader(csvfile)\n",
    "        headings=next(reader)\n",
    "        print (\"Reading csv file with headers:\\n  \",\"\\n   \".join(headings),\"\\n\")\n",
    "        x=[]\n",
    "        for row in reader:\n",
    "            x.append(row)    \n",
    "    return(np.array(x,dtype=float).T)   # returns data with one column for each multidimensional sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv file with headers:\n",
      "   MeanIP\n",
      "   StdIP\n",
      "   KurtosisIP\n",
      "   SkewIP\n",
      "   MeanDM\n",
      "   StdDM\n",
      "   KurtosisDM\n",
      "   SkewDM\n",
      "   Class \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = data_load(\"HTRU_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "\n",
    "# SVM\n",
    "SVM_pa_C = [0.1, 1, 10]\n",
    "\n",
    "for pa_C in SVM_pa_C:\n",
    "    \n",
    "    clf = LinearSVC(C=pa_C, dual=False)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(x):\n",
    "        clf.fit(x[train_index, :8], x[train_index, 8])\n",
    "        y_pred = clf.predict(x[test_index, :8])\n",
    "        accuracy.append(accuracy_score(x[test_index, 8], y_pred))\n",
    "        precision.append(precision_score(x[test_index, 8], y_pred))\n",
    "        recall.append(recall_score(x[test_index, 8], y_pred))\n",
    "    \n",
    "    table.append([np.mean(accuracy), np.mean(precision), np.mean(recall), np.std(accuracy), np.std(precision), np.std(recall)])\n",
    "    \n",
    "# Decision Tree\n",
    "dt_max_depth = [3,4,6]\n",
    "\n",
    "for pa_max_depth in dt_max_depth:\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth=pa_max_depth)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(x):\n",
    "        clf.fit(x[train_index, :8], x[train_index, 8])\n",
    "        y_pred = clf.predict(x[test_index, :8])\n",
    "        accuracy.append(accuracy_score(x[test_index, 8], y_pred))\n",
    "        precision.append(precision_score(x[test_index, 8], y_pred))\n",
    "        recall.append(recall_score(x[test_index, 8], y_pred))\n",
    "    \n",
    "    table.append([np.mean(accuracy), np.mean(precision), np.mean(recall), np.std(accuracy), np.std(precision), np.std(recall)])\n",
    "    \n",
    "# Random Forest\n",
    "num_tree = [5,11,13]\n",
    "\n",
    "for pa_num_tree in num_tree:\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=pa_num_tree, max_depth=5)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(x):\n",
    "        clf.fit(x[train_index, :8], x[train_index, 8])\n",
    "        y_pred = clf.predict(x[test_index, :8])\n",
    "        accuracy.append(accuracy_score(x[test_index, 8], y_pred))\n",
    "        precision.append(precision_score(x[test_index, 8], y_pred))\n",
    "        recall.append(recall_score(x[test_index, 8], y_pred))\n",
    "    \n",
    "    table.append([np.mean(accuracy), np.mean(precision), np.mean(recall), np.std(accuracy), np.std(precision), np.std(recall)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accuracy</th>\n",
       "      <th>mean precision</th>\n",
       "      <th>mean recall</th>\n",
       "      <th>accuracy std</th>\n",
       "      <th>precision std</th>\n",
       "      <th>recall std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Linear SVM with C = 0.1</td>\n",
       "      <td>0.977373</td>\n",
       "      <td>0.897046</td>\n",
       "      <td>0.780514</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>0.111252</td>\n",
       "      <td>0.063226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Linear SVM with C = 1</td>\n",
       "      <td>0.977708</td>\n",
       "      <td>0.898326</td>\n",
       "      <td>0.782744</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.111765</td>\n",
       "      <td>0.064500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Linear SVM with C = 10</td>\n",
       "      <td>0.977708</td>\n",
       "      <td>0.898326</td>\n",
       "      <td>0.782744</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.111765</td>\n",
       "      <td>0.064500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Decision Tree with max_depth = 3</td>\n",
       "      <td>0.977987</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.840712</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.120281</td>\n",
       "      <td>0.042894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Decision Tree with max_depth = 4</td>\n",
       "      <td>0.978602</td>\n",
       "      <td>0.866008</td>\n",
       "      <td>0.823791</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.117845</td>\n",
       "      <td>0.056560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Decision Tree with max_depth = 6</td>\n",
       "      <td>0.978657</td>\n",
       "      <td>0.861063</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.127188</td>\n",
       "      <td>0.076631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest with num_tree = 5</td>\n",
       "      <td>0.977317</td>\n",
       "      <td>0.873871</td>\n",
       "      <td>0.781326</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.133071</td>\n",
       "      <td>0.086046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest with num_tree = 11</td>\n",
       "      <td>0.977372</td>\n",
       "      <td>0.880527</td>\n",
       "      <td>0.788608</td>\n",
       "      <td>0.006907</td>\n",
       "      <td>0.107719</td>\n",
       "      <td>0.077544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest with num_tree = 13</td>\n",
       "      <td>0.977987</td>\n",
       "      <td>0.883338</td>\n",
       "      <td>0.793359</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.111242</td>\n",
       "      <td>0.071455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  mean accuracy  mean precision  mean recall  \\\n",
       "Linear SVM with C = 0.1                0.977373        0.897046     0.780514   \n",
       "Linear SVM with C = 1                  0.977708        0.898326     0.782744   \n",
       "Linear SVM with C = 10                 0.977708        0.898326     0.782744   \n",
       "Decision Tree with max_depth = 3       0.977987        0.848144     0.840712   \n",
       "Decision Tree with max_depth = 4       0.978602        0.866008     0.823791   \n",
       "Decision Tree with max_depth = 6       0.978657        0.861063     0.816999   \n",
       "Random Forest with num_tree = 5        0.977317        0.873871     0.781326   \n",
       "Random Forest with num_tree = 11       0.977372        0.880527     0.788608   \n",
       "Random Forest with num_tree = 13       0.977987        0.883338     0.793359   \n",
       "\n",
       "                                  accuracy std  precision std  recall std  \n",
       "Linear SVM with C = 0.1               0.008142       0.111252    0.063226  \n",
       "Linear SVM with C = 1                 0.008086       0.111765    0.064500  \n",
       "Linear SVM with C = 10                0.008086       0.111765    0.064500  \n",
       "Decision Tree with max_depth = 3      0.006209       0.120281    0.042894  \n",
       "Decision Tree with max_depth = 4      0.006496       0.117845    0.056560  \n",
       "Decision Tree with max_depth = 6      0.005731       0.127188    0.076631  \n",
       "Random Forest with num_tree = 5       0.006173       0.133071    0.086046  \n",
       "Random Forest with num_tree = 11      0.006907       0.107719    0.077544  \n",
       "Random Forest with num_tree = 13      0.006522       0.111242    0.071455  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name = ['mean accuracy', 'mean precision', 'mean recall', 'accuracy std', 'precision std', 'recall std']\n",
    "idx_name = ['Linear SVM with C = 0.1', 'Linear SVM with C = 1', 'Linear SVM with C = 10', \n",
    "            'Decision Tree with max_depth = 3', 'Decision Tree with max_depth = 4','Decision Tree with max_depth = 6',\n",
    "            'Random Forest with num_tree = 5', 'Random Forest with num_tree = 11', 'Random Forest with num_tree = 13']\n",
    "pd.DataFrame(table, columns=col_name, index=idx_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\text{In this dataset, there are $1639$ positive examples and $16259$ negative examples, so the ratio of negative examples is}\\\\\n",
    "\\text{approximately $90.84\\%$, which is really high. As a result, even if we blindly predict each example to be negative, we can}\\\\\n",
    "\\text{still get an accuracy of $0.9084$ that is higher than all the mean precisions and mean recalls in the above table. In other}\\\\\n",
    "\\text{words, it is really easy to get true negative while hard to get true positive. Since precision and recall are based on}\\\\\n",
    "\\text{predicted positive and actual positive, respectively, and that accuracy is based on the overall examples where negative}\\\\\n",
    "\\text{examples have a ratio of about $90.84\\%$, it is reasonable that accuracy has a high value compared to precision and recall.}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\text{In my opinion, the decision-tree classifier with max_depth=3 performs the best. Accuracy of each classifier is really close to}\\\\\n",
    "\\text{each other and really high, and it is relatively easy to get a high accuracy according to problem 1.2. Thus, mean accuracy should}\\\\\n",
    "\\text{not be the key metrics to judge which classifier is the best. Since the ratio of positive examples in this dataset is just about}\\\\\n",
    "\\text{$9.16\\%$, which is really low, the trained classifier will tend to predict negative. Therefore, I think the capability to have the}\\\\ \n",
    "\\text{actual positive examples predicted as positive should be emphasized. In other words, mean recall should be the key metrics to juege}\\\\ \n",
    "\\text{which classifier is the best. As a result, the decision-tree classifier with max_depth=3 should be the best one, because it has the}\\\\ \n",
    "\\text{highest mean recall value and its mean recall value is considerably higher than other classifiers' mean recall values. Even though}\\\\ \n",
    "\\text{the mean precision of the decision-tree classifier with max_depth=3 is the lowest among these classifiers, it is still high enough}\\\\ \n",
    "\\text{to allow it to be the best. To conclude, the decision-tree classifier with max_depth=3 performs the best, because it has the highest}\\\\\n",
    "\\text{mean recall value, equivalently, the strongest capability to have the actural positive examples predicted as positive.}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "z_1 = x\\cdot w_1 + b_1,\\ a_1 = \\sigma(z_1)\\\\\n",
    "z_4 = a_1\\cdot w_4 + a_2\\cdot w_5 + a_3\\cdot w_6 + b_4,\\ a_4 = \\sigma(z_4)\\\\\n",
    "\\hat{y} = a_4 = \\sigma(z_4) = \\sigma(a_1\\cdot w_4 + a_2\\cdot w_5 + a_3\\cdot w_6 + b_4)\\\\\n",
    "\\ \\ = \\sigma(\\sigma(z_1)\\cdot w_4 + \\sigma(z_2)\\cdot w_5 + \\sigma(z_3)\\cdot w_6 + b_4)\\\\\n",
    "\\ \\ = \\sigma(\\sigma(x_1\\cdot w_1 + b_1)\\cdot w_4 + \\sigma(x_1\\cdot w_2 + b_2)\\cdot w_5 \n",
    "+ \\sigma(x_1\\cdot w_3 + b_3)\\cdot w_6 + b_4)\\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "L_i = (\\hat{y}_i - y_i)^2\\\\\n",
    "\\frac{\\partial L_i}{\\partial w_1} = \\frac{\\partial L_i}{\\partial \\hat{y}_i} \\frac{\\partial \\hat{y}_i}{\\partial a_4}\n",
    "\\frac{\\partial a_4}{\\partial z_{4i}} \\frac{\\partial z_{4i}}{\\partial a_1} \\frac{\\partial a_1}{\\partial z_{1i}} \n",
    "\\frac{\\partial z_{1i}}{\\partial w_1}\\\\\n",
    "\\frac{\\partial L_i}{\\partial w_4} = \\frac{\\partial L_i}{\\partial \\hat{y}_i} \\frac{\\partial \\hat{y}_i}{\\partial a_4}\n",
    "\\frac{\\partial a_4}{\\partial z_{4i}} \\frac{\\partial z_{4i}}{\\partial w_4}\\\\\n",
    "\\frac{\\partial L_i}{\\partial b_1} = \\frac{\\partial L_i}{\\partial \\hat{y}_i} \\frac{\\partial \\hat{y}_i}{\\partial a_4}\n",
    "\\frac{\\partial a_4}{\\partial z_{4i}} \\frac{\\partial z_{4i}}{\\partial a_1} \\frac{\\partial a_1}{\\partial z_{1i}} \n",
    "\\frac{\\partial z_{1i}}{\\partial b_1}\\\\\n",
    "\\frac{\\partial L_i}{\\partial b_4} = \\frac{\\partial L_i}{\\partial \\hat{y}_i} \\frac{\\partial \\hat{y}_i}{\\partial a_4}\n",
    "\\frac{\\partial a_4}{\\partial z_{4i}} \\frac{\\partial z_{4i}}{\\partial b_4}\\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\because \\frac{\\partial L_i}{\\partial \\hat{y}_i} = 2 (\\hat{y}_i-y_i),\\\n",
    "\\frac{\\partial \\hat{y}_i}{\\partial a_4} = 1\\\\\n",
    "\\because \\frac{\\partial a_4}{\\partial z_{4i}} = \\sigma(z_{4i})(1-\\sigma(z_{4i})),\\\n",
    "\\frac{\\partial z_{4i}}{\\partial a_1} = w_4\\\\\n",
    "\\because \\frac{\\partial a_1}{\\partial z_{1i}} = \\sigma(z_{1i})(1-\\sigma(z_{1i})),\\\n",
    "\\frac{\\partial z_{1i}}{\\partial w_1} = x_i\\\\\n",
    "\\because \\frac{\\partial z_{4i}}{\\partial w_4} = a_1 = \\sigma(z_{1i}),\\\n",
    "\\frac{\\partial z_{1i}}{\\partial b_1} = 1,\\\n",
    "\\frac{\\partial z_{4i}}{\\partial b_4} = 1\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\therefore \\frac{\\partial L_i}{\\partial w_1} = 2 (\\hat{y}_i-y_i)\\cdot \\sigma(z_{4i})(1-\\sigma(z_{4i}))\\cdot w_4\\cdot \n",
    "\\sigma(z_{1i})(1-\\sigma(z_{1i}))\\cdot x_i\\\\\n",
    "\\therefore \\frac{\\partial L_i}{\\partial w_4} = 2 (\\hat{y}_i-y_i)\\cdot \\sigma(z_{4i})(1-\\sigma(z_{4i}))\\cdot \\sigma(z_{1i})\\\\\n",
    "\\therefore \\frac{\\partial L_i}{\\partial b_1} = 2 (\\hat{y}_i-y_i)\\cdot \\sigma(z_{4i})(1-\\sigma(z_{4i}))\\cdot w_4\\cdot \n",
    "\\sigma(z_{1i})(1-\\sigma(z_{1i}))\\\\\n",
    "\\therefore \\frac{\\partial L_i}{\\partial b_4} = 2 (\\hat{y}_i-y_i)\\cdot \\sigma(z_{4i})(1-\\sigma(z_{4i}))\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "w_1^+ = w_1 - \\eta \\frac{\\partial L_1}{\\partial w_1}\\\\\n",
    "\\text{from Problem 2.2, we have}\\\\\n",
    "w_1^+ = w_1 - \\eta \\frac{\\partial L_1}{\\partial \\hat{y}_1} \\frac{\\partial \\hat{y}_1}{\\partial a_4}\n",
    "\\frac{\\partial a_4}{\\partial z_{41}} \\frac{\\partial z_{41}}{\\partial a_1} \\frac{\\partial a_1}{\\partial z_{11}} \n",
    "\\frac{\\partial z_{11}}{\\partial w_1}\\\\\n",
    "\\ \\ \\ \\ \\ = w_1 - \\eta \\cdot [2 (\\hat{y}_1-y_1)\\cdot \\sigma(z_{41})(1-\\sigma(z_{41}))\\cdot w_4\\cdot \n",
    "\\sigma(z_{11})(1-\\sigma(z_{11}))\\cdot x_1]\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "w_1^+ = w_1 - \\eta \\frac{\\partial L}{\\partial w_1} = w_1 - \\eta \\cdot \\frac{1}{n} \\sum_{i=1}^{n}\\frac{\\partial L_i}{\\partial w_1}\\\\\n",
    "\\text{from Problem 2.2, we have}\\\\\n",
    "w_1^+ = w_1 - \\eta \\cdot \\frac{1}{n} \\sum_{i=1}^{n}\\frac{\\partial L_i}{\\partial w_1}\n",
    "= w_1 - \\eta \\cdot \\frac{1}{n} \\sum_{i=1}^{n}\n",
    "\\frac{\\partial L_i}{\\partial \\hat{y}_i} \\frac{\\partial \\hat{y}_i}{\\partial a_4}\n",
    "\\frac{\\partial a_4}{\\partial z_{4i}} \\frac{\\partial z_{4i}}{\\partial a_1} \\frac{\\partial a_1}{\\partial z_{1i}} \n",
    "\\frac{\\partial z_{1i}}{\\partial w_1}\\\\\n",
    "\\ \\ \\ \\ \\ = w_1 - \\frac{2\\eta}{n} \\sum_{i=1}^{n}  (\\hat{y}_i-y_i)\\cdot \\sigma(z_{4i})(1-\\sigma(z_{4i}))\\cdot w_4\\cdot \n",
    "\\sigma(z_{1i})(1-\\sigma(z_{1i}))\\cdot x_i\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\text{Sigmoid activation}\\\\\n",
    "\\bullet \\text{advantage: It does not blow up activation, because the sigmoid function is bounded in $[0,1]$.}\\\\\n",
    "\\bullet \\text{disadvantage: It has the vanishing gradient problem in deep networks, because the derivative of sigmoid function is}\\\\\n",
    "\\ \\ \\ \\text{almost zero when the input is greater than $6$ or less than $-6$.}\\\\\n",
    "\\text{ReLU activation}\\\\\n",
    "\\bullet \\text{advantage: It is more computationally efficient than sigmoid activation, because it just needs to pick $max(0,z)$,}\\\\\n",
    "\\ \\ \\ \\text{instead of performing expensive exponential computations as in sigmoid activation.}\\\\\n",
    "\\bullet \\text{disadvantage: It tends to blow up activation, because its value is not restricted and can be arbitrarily large.}\n",
    "$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
